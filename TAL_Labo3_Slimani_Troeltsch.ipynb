{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 3<br/>*Depedency parser* pour le français dans spaCy\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Évaluer l'analyseur syntaxique en dépendances fourni par spaCy dans le modèle `fr_core_news_sm`, puis le comparer avec un analyseur entraîné par vous-mêmes.  Les données sont les mêmes qu'au Labo 2 et la démarche du labo est similaire aussi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prise en main de l'analyseur de spaCy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\") # charge la pipeline"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a.** Pour la pipeline `fr_core_news_sm`, veuillez afficher les traitements disponibles, puis désactiver tous les traitements sauf `tok2vec`, `morphologizer` et `parser`, puis vérifiez que la désactivation a bien fonctionné."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:35:27.327495Z",
     "start_time": "2025-04-03T11:35:27.309476Z"
    }
   },
   "source": [
    "# Afficher les traitements disponibles dans la pipeline fr_core_news_sm\n",
    "print(\"Composants disponibles dans la pipeline avant désactivation :\")\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Désactiver tous les composants sauf tok2vec, morphologizer et parser\n",
    "disabled_pipes = []\n",
    "for pipe_name in nlp.pipe_names:\n",
    "    if pipe_name not in ['tok2vec', 'morphologizer', 'parser']:\n",
    "        nlp.disable_pipe(pipe_name)\n",
    "        disabled_pipes.append(pipe_name)\n",
    "\n",
    "# Vérifier que la désactivation a bien fonctionné\n",
    "print(\"\\nComposants désactivés :\", disabled_pipes)\n",
    "print(\"\\nComposants actifs dans la pipeline après désactivation :\")\n",
    "print(nlp.pipe_names)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composants disponibles dans la pipeline avant désactivation :\n",
      "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "\n",
      "Composants désactivés : ['attribute_ruler', 'lemmatizer', 'ner']\n",
      "\n",
      "Composants actifs dans la pipeline après désactivation :\n",
      "['tok2vec', 'morphologizer', 'parser']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:35:32.982817Z",
     "start_time": "2025-04-03T11:35:32.963982Z"
    }
   },
   "source": [
    "from spacy.lang.fr.examples import sentences\n",
    "s1 = sentences[2] # prenons la 3e phrase comme exemple"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b.** Veuillez analyser `s1` avec la pipeline `nlp` puis afficher chaque token, son POS tag, et son étiquette indiquant la relation de dépendance (entre crochets, après le token).  Quelle information essentielle manque dans cette représentation ?\n",
    "\n",
    "Note : le *morphologizer* fournit aussi les POS tags.  La liste des tags possibles est [fournie par spaCy](https://spacy.io/models/fr#fr_core_news_md-labels).  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:35:38.758381Z",
     "start_time": "2025-04-03T11:35:38.711944Z"
    }
   },
   "source": [
    "doc = nlp(s1)\n",
    "for token in doc:\n",
    "    print(f\"{token.text} {token.pos_} [{token.dep_}]\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San PRON [nsubj]\n",
      "Francisco PROPN [flat:name]\n",
      "envisage VERB [ROOT]\n",
      "d' ADP [case]\n",
      "interdire NOUN [obl:arg]\n",
      "les DET [det]\n",
      "robots NOUN [obj]\n",
      "coursiers ADJ [amod]\n",
      "sur ADP [case]\n",
      "les DET [det]\n",
      "trottoirs NOUN [nmod]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Dans cette représentation, l'information essentielle qui manque est l'indication du parent de chaque token dans l'arbre de dépendances (à quel mot chaque token est rattaché). Nous voyons bien le type de relation (nsubj, flat:name, ROOT, etc.) mais pas vers quel mot cette relation est dirigée, ce qui rend difficile la compréhension complète de la structure syntaxique de la phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c.** Veuillez afficher tous les groupes de mots qui sont soit des `nsubj` soit des `obj` dans la phrase `s1` (c'est à dire les sujets et les objets du verbe).   Indication : le sous-arbre d'un token *t* est accessible comme `t.subtree`. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:35:42.230310Z",
     "start_time": "2025-04-03T11:35:42.210400Z"
    }
   },
   "source": [
    "# Identifier les tokens qui sont des sujets (nsubj) ou des objets (obj)\n",
    "nsubj_obj_tokens = [token for token in doc if token.dep_ in [\"nsubj\", \"obj\"]]\n",
    "\n",
    "# Afficher les sous-arbres correspondants\n",
    "print(\"Groupes de mots qui sont des sujets ou des objets dans la phrase :\")\n",
    "for token in nsubj_obj_tokens:\n",
    "    print(token.text, [child.text for child in token.children], token.dep_)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupes de mots qui sont des sujets ou des objets dans la phrase :\n",
      "San ['Francisco'] nsubj\n",
      "robots ['les', 'coursiers', 'trottoirs'] obj\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Évaluation quantitative de l'analyseur sur une phrase \n",
    "\n",
    "Les données sont les mêmes que celles du Labo 2.  Vous les avez déjà transformées au Labo 2 dans un format utilisable par spaCy, dans un dossier nommé `Labo2/spacy_data` que vous allez réutiliser.  Les trois fichiers contiennent des phrases en français annotées aussi avec les arbres de dépendance.  Le fichier `fr-ud-train.conllu` est destiné à l'entraînement, `fr-ud-dev.conllu` au réglage des paramètres, et `fr-ud-test.conllu` à l'évaluation finale.\n",
    "\n",
    "**2a.** En inspectant un des fichiers d'origine avec un éditeur texte, veuillez indiquer dans quelles colonnes se trouvent les informations sur les relations de dépendance, et comment elles sont représentées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les informations sur les relations de dépendance sont dans la 8ème colonne. Elles sont représentées par le nom de la relation de dépendance.\n",
    "# Example : \"nsubj\" pour \"nom sujet\", \"ROOT\" pour le noeud racine, \"det\" pour \"déterminant\", \"amod\" pour \"adjectif modificateur\", \"punct\" pour \"ponctuation\", etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:40:37.080842Z",
     "start_time": "2025-04-03T11:40:37.049966Z"
    }
   },
   "source": [
    "from spacy.tokens import DocBin, Doc\n",
    "test_data = DocBin().from_disk(\"C:/Users/faxiz/OneDrive/Bureau/HEIG-VD/Semestre8/TAL/Laboratoire/L2/TAL-L2/spacy_data/fr-ud-test.spacy\")\n",
    "# for doc in test_data.get_docs(nlp.vocab):  # exemple\n",
    "#     for sent in doc.sents:\n",
    "#         print(sent)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b**. On rapplle que les données des fichiers convertis peuvent être chargées dans un objet de type `DocBin`.  Ici, un tel objet contient un ensemble de documents, chacun contenant 10 phrases.  Chaque document est un objet de type `Doc`.  Le code donné ci-dessous vous permet de charger les données de test et vous montre comment les afficher.\n",
    "\n",
    "* Veuillez stocker la *7e phrase du 2e document des données de test* dans une variable nommée `s2`.\n",
    "* Veuillez afficher cette phrase (elle commence par \"Trois ans\")."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:40:45.353008Z",
     "start_time": "2025-04-03T11:40:45.257977Z"
    }
   },
   "source": [
    "docs = list(test_data.get_docs(nlp.vocab))\n",
    "if len(docs) > 1:\n",
    "    doc2 = list(docs[1].sents)\n",
    "    if len(doc2) > 6:\n",
    "        s2 = doc2[6]\n",
    "        print(s2.text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trois ans plus tard, il tient un discours sur la crise.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** En utilisant `displaCy` comme expliqué [ici](https://spacy.io/usage/visualizers) veuillez afficher graphiquement l'arbre de dépendances de la phrase `s2` tel qu'il est fourni dans les données.  Pour être affichée, la phrase doit être transformée en objet `Doc`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:40:53.748864Z",
     "start_time": "2025-04-03T11:40:53.735427Z"
    }
   },
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import HTML, display\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:40:56.326866Z",
     "start_time": "2025-04-03T11:40:56.304465Z"
    }
   },
   "source": [
    "display(HTML('<span class=\"tex2jax_ignore\">{}</span>'.format(\n",
    "    displacy.render(s2, style=\"dep\", jupyter=False)\n",
    ")))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"380f21b7572b4c318c67b4445274b623-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Trois</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">ans</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">plus</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">tard,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">il</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">tient</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">un</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">discours</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">sur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">crise.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-380f21b7572b4c318c67b4445274b623-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-380f21b7572b4c318c67b4445274b623-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d.** En utilisant `displaCy`, veuillez également afficher l'arbre de dépendances calculé par la pipeline `nlp` pour cette même phrase `s2`.  Pour être analysée et affichée, la phrase doit être transformée en objet `Doc`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:41:27.279854Z",
     "start_time": "2025-04-03T11:41:27.260935Z"
    }
   },
   "source": [
    "nlpS2 = nlp(s2.text)\n",
    "\n",
    "display(HTML('<span class=\"tex2jax_ignore\">{}</span>'.format(\n",
    "    displacy.render(nlpS2, style=\"dep\", jupyter=False)\n",
    ")))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"e0eb5ae1002e4bbb970354a12185621f-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Trois</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">ans</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">plus</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">tard,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">il</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">tient</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">un</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">discours</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">sur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">crise.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-4\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-6\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-7\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e0eb5ae1002e4bbb970354a12185621f-0-8\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e0eb5ae1002e4bbb970354a12185621f-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2e.** Veuillez comparer les deux arbres de dépendances et indiquer ici les différences.  Quel est le taux de correction de la pipeline `nlp` sur cette phrase ?\n",
    "\n",
    "Suggestion : il peut être utile de sauvegarder les deux arbres dans des images SVG, en écrivant dans un fichier le résultat retourné par `displacy.render` avec l'option `jupyter = False`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:49:16.220774Z",
     "start_time": "2025-04-03T11:49:16.200090Z"
    }
   },
   "source": [
    "# Comparer les structures de dépendances\n",
    "correct_deps = 0\n",
    "total_deps = 0\n",
    "\n",
    "s2_deps = [(token.i, token.dep_, token.head.i) for token in s2]\n",
    "nlpS2_deps = [(token.i, token.dep_, token.head.i) for token in nlpS2]\n",
    "\n",
    "# Afficher les dépendances côte à côte pour comparaison\n",
    "print(\"Original vs. Predicted\")\n",
    "print(\"=======================\")\n",
    "for i, (orig, pred) in enumerate(zip(s2_deps, nlpS2_deps)):\n",
    "    orig_token = s2[i].text\n",
    "    is_correct = orig[1] == pred[1] and (orig[2] - 161) == pred[2]\n",
    "    \n",
    "    if is_correct:\n",
    "        correct_deps += 1\n",
    "    total_deps += 1\n",
    "    \n",
    "    print(f\"{orig_token}: [{orig[1]}] {s2[(orig[2] - 161)].text if (orig[2] - 161) < len(s2) else 'ROOT'} vs [{pred[1]}] {nlpS2[pred[2]].text if pred[2] < len(nlpS2) else 'ROOT'} {'✓' if is_correct else '✗'}\")\n",
    "\n",
    "# Calculer le taux de correction\n",
    "accuracy = correct_deps / total_deps if total_deps > 0 else 0\n",
    "print(f\"\\nTaux de correction: {accuracy:.3f} ({correct_deps}/{total_deps})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs. Predicted\n",
      "=======================\n",
      "Trois: [nummod] ans vs [nummod] ans ✓\n",
      "ans: [obl] tient vs [obl:mod] plus ✗\n",
      "plus: [advmod] tard vs [advmod] tard ✓\n",
      "tard: [advmod] ans vs [ROOT] tard ✗\n",
      ",: [punct] tient vs [punct] tient ✓\n",
      "il: [nsubj] tient vs [nsubj] tient ✓\n",
      "tient: [ROOT] tient vs [ROOT] tient ✓\n",
      "un: [det] discours vs [det] discours ✓\n",
      "discours: [obj] tient vs [obj] tient ✓\n",
      "sur: [case] crise vs [case] crise ✓\n",
      "la: [det] crise vs [det] crise ✓\n",
      "crise: [nmod] discours vs [nmod] discours ✓\n",
      ".: [punct] tient vs [punct] tient ✓\n",
      "\n",
      "Taux de correction: 0.846 (11/13)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f.**  Veuillez appliquer le `Scorer` de spaCy (voir Labo 2) et afficher les deux scores qu'il produit pour l'analyse en dépendances (avec trois décimales après la virgule).  Retrouvez-vous les scores de la question précédente ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:49:37.546240Z",
     "start_time": "2025-04-03T11:49:37.536435Z"
    }
   },
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.training import Example"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:49:39.858170Z",
     "start_time": "2025-04-03T11:49:39.700990Z"
    }
   },
   "source": [
    "# Créer un scorer et une exemple pour l'évaluation\n",
    "scorer = Scorer()\n",
    "\n",
    "# Créer un exemple pour l'évaluation\n",
    "example = Example(nlpS2, s2.as_doc())\n",
    "\n",
    "# Calculer les scores (scorer.score prend une liste d'exemples)\n",
    "scores = scorer.score([example])\n",
    "\n",
    "# Afficher les scores des dépendances avec trois décimales\n",
    "print(f\"UAS: {scores['dep_uas']:.3f}\")  # Unlabeled Attachment Score\n",
    "print(f\"LAS: {scores['dep_las']:.3f}\")  # Labeled Attachment Score\n",
    "\n",
    "# Comparer avec les résultats de la question précédente\n",
    "# La justification est imprimée pour expliquer la différence/similarité\n",
    "print(\"\\nComparaison avec le taux de correction précédent:\")\n",
    "print(f\"Taux précédent: {correct_deps / total_deps:.3f}\")\n",
    "print(\"La différence entre les scores peut être expliquée par la méthode de comparaison.\")\n",
    "print(\"Dans la question précédente, le score inclut la comparaison de la ponctuation. Le score UAS/LAS ne le fait pas.\")\n",
    "print(f\"Si on exlut la ponctuation, le score est le meme: {(correct_deps - 2) / (total_deps - 2):.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS: 0.818\n",
      "LAS: 0.818\n",
      "\n",
      "Comparaison avec le taux de correction précédent:\n",
      "Taux précédent: 0.846\n",
      "La différence entre les scores peut être expliquée par la méthode de comparaison.\n",
      "Dans la question précédente, le score inclut la comparaison de la ponctuation. Le score UAS/LAS ne le fait pas.\n",
      "Si on exlut la ponctuation, le score est le meme: 0.818\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Évaluation du *dependency parser* de `fr_core_news_sm` sur l'ensemble des phrases test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a.** Veuillez calculer les deux scores qui caractérisent l'analyseur en dépendances de la pipeline `nlp` sur toutes les données de test présentes dans `test_data`.  Comment se comparent ces scores avec ceux mentionnés [dans la documentation de fr_core_news_sm](https://spacy.io/models/fr#fr_core_news_sm) ?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T11:52:57.502384Z",
     "start_time": "2025-04-03T11:52:55.392979Z"
    }
   },
   "source": [
    "# Calculate both scores for all test data\n",
    "total_examples = []\n",
    "\n",
    "# Get all docs from test data\n",
    "test_docs = list(test_data.get_docs(nlp.vocab))\n",
    "\n",
    "# Process each document and create examples for scoring\n",
    "for doc in test_docs:\n",
    "    for sent in doc.sents:\n",
    "        # Create a Doc object from the text of the sentence for processing with nlp\n",
    "        pred_doc = nlp(sent.text)\n",
    "        # Create an Example object for each sentence\n",
    "        example = Example(pred_doc, sent.as_doc())\n",
    "        total_examples.append(example)\n",
    "\n",
    "# Score all examples\n",
    "full_scorer = Scorer()\n",
    "scores = full_scorer.score(total_examples)\n",
    "\n",
    "# Display the scores\n",
    "print(f\"UAS (Unlabeled Attachment Score): {scores['dep_uas']:.3f}\")\n",
    "print(f\"LAS (Labeled Attachment Score): {scores['dep_las']:.3f}\")\n",
    "\n",
    "# Compare with the documented scores for fr_core_news_sm\n",
    "print(\"\\nDocumented scores for fr_core_news_sm:\")\n",
    "print(\"UAS (documented): 0.88\")\n",
    "print(\"LAS (documented): 0.84\")\n",
    "print(\"\\nDifference from documented scores:\")\n",
    "print(f\"UAS difference: {scores['dep_uas'] - 0.88:.3f}\")\n",
    "print(f\"LAS difference: {scores['dep_las'] - 0.84:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS (Unlabeled Attachment Score): 0.741\n",
      "LAS (Labeled Attachment Score): 0.613\n",
      "\n",
      "Documented scores for fr_core_news_sm:\n",
      "UAS (documented): 0.88\n",
      "LAS (documented): 0.84\n",
      "\n",
      "Difference from documented scores:\n",
      "UAS difference: -0.139\n",
      "LAS difference: -0.227\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** Le *scorer* fournit également des scores détaillés pour chaque type de relation de dépendances.  Veuillez afficher ces valeurs dans un tableau proprement formaté, trié par score F1 décroissant, avec trois décimales."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    },
    "ExecuteTime": {
     "end_time": "2025-04-03T11:53:00.912020Z",
     "start_time": "2025-04-03T11:53:00.904510Z"
    }
   },
   "source": [
    "# Calculate scores for each dependency type\n",
    "scores_by_type = scores['dep_las_per_type']\n",
    "\n",
    "#print(scores_by_type)\n",
    "\n",
    "# Sort the types by f score\n",
    "sorted_types = sorted(scores_by_type.items(), key=lambda x: x[1]['f'], reverse=True)\n",
    "\n",
    "# Display types with top f scores\n",
    "print(f\"{'Type':<20} {'Precision':>10} {'Recall':>10} {'F-score':>10}\")\n",
    "print(\"-\" * 52)\n",
    "\n",
    "# Print scores for each type, aligned in columns\n",
    "for dep_type, score in sorted_types:\n",
    "    print(f\"{dep_type:<20} {score['p']:>10.3f} {score['r']:>10.3f} {score['f']:>10.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                  Precision     Recall    F-score\n",
      "----------------------------------------------------\n",
      "det                       0.935      0.760      0.838\n",
      "cc                        0.806      0.787      0.796\n",
      "case                      0.860      0.728      0.789\n",
      "mark                      0.747      0.779      0.763\n",
      "nsubj:pass                0.683      0.860      0.761\n",
      "aux:pass                  0.636      0.925      0.754\n",
      "cop                       0.729      0.734      0.731\n",
      "nsubj                     0.787      0.677      0.727\n",
      "root                      0.630      0.791      0.701\n",
      "amod                      0.665      0.740      0.701\n",
      "advmod                    0.698      0.692      0.695\n",
      "nummod                    0.762      0.637      0.694\n",
      "obj                       0.695      0.685      0.690\n",
      "flat:name                 0.679      0.622      0.649\n",
      "nmod                      0.590      0.595      0.592\n",
      "xcomp                     0.496      0.613      0.549\n",
      "acl:relcl                 0.519      0.547      0.532\n",
      "acl                       0.445      0.421      0.433\n",
      "iobj                      0.318      0.560      0.406\n",
      "advcl                     0.402      0.382      0.392\n",
      "ccomp                     0.476      0.317      0.381\n",
      "conj                      0.394      0.369      0.381\n",
      "fixed                     0.548      0.291      0.381\n",
      "appos                     0.455      0.254      0.326\n",
      "parataxis                 0.050      0.031      0.038\n",
      "obl                       0.000      0.000      0.000\n",
      "aux                       0.000      0.000      0.000\n",
      "dep                       0.000      0.000      0.000\n",
      "aux:tense                 0.000      0.000      0.000\n",
      "obl:mod                   0.000      0.000      0.000\n",
      "obl:arg                   0.000      0.000      0.000\n",
      "obl:agent                 0.000      0.000      0.000\n",
      "expl                      0.000      0.000      0.000\n",
      "expl:subj                 0.000      0.000      0.000\n",
      "expl:comp                 0.000      0.000      0.000\n",
      "obj:agent                 0.000      0.000      0.000\n",
      "aux:caus                  0.000      0.000      0.000\n",
      "nsubj:caus                0.000      0.000      0.000\n",
      "compound                  0.000      0.000      0.000\n",
      "expl:pass                 0.000      0.000      0.000\n",
      "iobj:agent                0.000      0.000      0.000\n",
      "discourse                 0.000      0.000      0.000\n",
      "flat:foreign              0.000      0.000      0.000\n",
      "vocative                  0.000      0.000      0.000\n",
      "csubj                     0.000      0.000      0.000\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entraîner puis évaluer un nouveau *parser* français dans spaCy\n",
    "\n",
    "Le but de cette partie est d'entraîner une pipeline spaCy pour le français sur les données de `fr-ud-train.conllu`, puis de comparer le modèle obtenu avec le modèle prêt-à-l'emploi testé au point précédent (voir le Labo 2 et les [instructions de spaCy](https://spacy.io/usage/training#quickstart)).\n",
    "\n",
    "**4a.** Paramétrage de l'entraînement :\n",
    "* générez un fichier de départ grâce à [l'interface web](https://spacy.io/usage/training#quickstart), en indiquant que vous gardez seulement les composants `morphologizer` et `parser` dans la pipeline ;\n",
    "* sauvegardez le code généré par spaCy dans un fichier local `base_config.cfg` ;\n",
    "* générez un fichier `config.cfg` sur votre ordinateur en exécutant la ligne de commande suivante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Auto-filled config with all values\n",
      "✔ Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez effectuer l'entraînement avec la ligne de commande suivante.  Faites plusieurs essais, d'abord avec un petit nombre d'époques (*à indiquer dans config.cfg*), pour estimer le temps nécessaire et observer les messages affichés.  Augmentez progressivement le nombre d'époques, jusqu'à ce que les scores sur le jeu de validation n'augmentent plus (si vous avez le temps).  Pendant combien d'époques entraînez-vous au final ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Note : il vaut mieux exécuter cela directement dans une fenêtre de commande, pour voir les logs en temps réel.\n",
    "!python -m spacy train config.cfg \\\n",
    "  --output ./myDEPparser1 \\\n",
    "  --paths.train ../Labo2/spacy_data/fr-ud-train.spacy \\\n",
    "  --paths.dev ../Labo2/spacy_data/fr-ud-dev.spacy \\\n",
    "  --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Après 1h10 le score semble converger vers 0.89. Il faut environ 3 epoches pour que le score converge vers 0.88.\n",
    "\n",
    "D'après l'analyse des données d'entraînement, il semble que le score commence à se stabiliser autour de 0.88 dès la 3ème époque. En effet, à partir de l'époque 3 (environ 5 800 itérations), les performances mesurées en termes de POS accuracy (93.49 %), de morph accuracy (93.08 %), de DEP_UAS (84.22 %) et de DEP_LAS (80.70 %) n'évoluent plus de manière significative.\n",
    "\n",
    "Passer à 6 ou 7 époques apporte un léger gain, avec un score qui oscille entre 0.88 et 0.89, mais au prix d'un temps d'entraînement beaucoup plus long. Par exemple, à la 6ème époque (10 000 itérations), le score atteint 0.89 avec une POS accuracy de 93.66 % et une DEP_LAS de 82.07 %, soit un gain relativement faible comparé au temps nécessaire pour atteindre ce résultat.\n",
    "\n",
    "Le compromis idéal semble donc se situer autour de 3 époques, car au-delà, l'amélioration est minime par rapport au temps investi. Cela permet d'obtenir un bon équilibre entre performance et efficacité du temps d'entraînement.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "E    #       LOSS TOK2VEC  LOSS MORPH...  LOSS PARSER  POS_ACC  MORPH_ACC  DEP_UAS  DEP_LAS  SENTS_F  SCORE\n",
    "---  ------  ------------  -------------  -----------  -------  ---------  -------  -------  -------  ------\n",
    "  0       0          0.00         224.53       504.38    34.04      29.37    24.62     9.44     0.15    0.24\n",
    "  0     200       4096.78       19210.50     37619.39    87.06      82.57    71.86    63.73    77.47    0.76\n",
    "  0     400       6086.66        9551.02     25690.90    90.13      87.90    76.39    70.25    86.82    0.81\n",
    "  0     600       6141.56        7278.40     22205.72    91.27      89.71    77.94    72.40    92.41    0.83\n",
    "  0     800       6830.94        6568.15     22035.75    91.80      90.43    79.78    74.66    92.66    0.84\n",
    "  0    1000       6455.47        5613.27     19689.17    92.22      91.04    81.22    75.96    94.69    0.85\n",
    "  0    1200       6854.82        5386.34     19385.73    92.45      91.52    81.36    76.63    95.68    0.85\n",
    "  0    1400       7042.58        4984.85     19073.12    92.66      91.73    81.96    77.27    94.28    0.86\n",
    "  1    1600       6834.45        4331.69     17409.78    92.86      91.95    82.00    77.35    94.31    0.86\n",
    "  1    1800       7003.48        3973.43     16621.10    92.82      92.08    81.82    77.44    95.18    0.86\n",
    "  1    2000       7270.27        4057.85     16804.29    92.93      92.26    82.64    78.30    95.09    0.87\n",
    "  1    2200       7784.44        3934.81     16801.02    93.00      92.29    83.08    78.73    95.64    0.87\n",
    "  1    2400       7957.06        4038.75     16813.73    93.11      92.45    83.41    79.41    95.22    0.87\n",
    "  1    2600       8364.00        4107.73     17427.06    93.08      92.50    83.46    79.37    96.11    0.87\n",
    "  1    2800       8355.31        4049.22     16900.29    93.22      92.75    83.92    79.85    95.92    0.87\n",
    "  2    3000       8685.64        3784.67     16781.63    93.43      92.83    83.94    79.98    96.16    0.88\n",
    "  2    3200       8460.56        3103.63     15042.00    93.33      92.84    83.55    79.33    95.85    0.87\n",
    "  2    3400       9045.77        3369.32     15400.25    93.30      92.82    83.78    79.85    96.08    0.87\n",
    "  2    3600       9386.08        3461.27     15310.16    93.33      92.88    83.89    79.88    96.02    0.87\n",
    "  2    3800       9457.70        3322.98     15019.68    93.37      92.90    83.92    79.88    95.64    0.88\n",
    "  2    4000       9689.28        3133.53     15105.83    93.34      92.87    83.83    80.02    95.85    0.88\n",
    "  2    4200       9882.13        3246.40     15017.14    93.39      92.97    84.03    80.30    95.69    0.88\n",
    "  3    4400       9699.11        3182.83     14413.34    93.38      92.99    84.34    80.36    96.03    0.88\n",
    "  3    4600      10288.52        2935.46     14225.83    93.36      92.99    84.42    80.70    96.30    0.88\n",
    "  3    4800      10484.30        2823.29     13812.97    93.44      93.04    84.14    80.37    95.92    0.88\n",
    "  3    5000      11164.27        2900.67     14236.61    93.37      93.03    83.79    80.24    95.32    0.88\n",
    "  3    5200      11474.90        2883.83     14451.45    93.39      92.98    84.35    80.53    95.95    0.88\n",
    "  3    5400      11381.88        2826.25     14024.44    93.49      93.08    84.22    80.70    96.01    0.88\n",
    "  3    5600      11518.92        2921.21     13766.86    93.52      93.10    84.48    80.75    95.51    0.88\n",
    "  3    5800      11825.22        2959.30     13940.46    93.61      93.10    84.87    81.01    96.13    0.88\n",
    "  4    6000      11401.72        2456.21     12922.77    93.58      93.15    84.87    81.29    95.83    0.88\n",
    "  4    6200      12716.10        2614.73     13143.19    93.51      93.06    84.84    81.06    96.36    0.88\n",
    "  4    6400      12803.21        2547.68     12967.38    93.51      93.16    84.79    81.07    95.34    0.88\n",
    "  4    6600      13767.46        2677.54     13708.22    93.59      93.19    84.53    81.06    96.06    0.88\n",
    "  4    6800      13726.32        2587.43     13400.85    93.64      93.30    84.51    80.94    96.09    0.88\n",
    "  4    7000      13754.91        2721.75     13463.51    93.65      93.28    84.73    81.17    96.46    0.88\n",
    "  4    7200      13792.97        2600.69     13299.43    93.61      93.17    84.86    81.30    95.85    0.88\n",
    "  5    7400      13637.91        2553.52     12850.60    93.55      93.20    85.10    81.55    96.47    0.88\n",
    "  5    7600      14250.57        2280.12     12321.21    93.51      93.19    84.70    81.20    95.77    0.88\n",
    "  5    7800      15413.42        2403.21     12570.02    93.62      93.25    84.85    81.33    95.71    0.88\n",
    "  5    8000      15926.62        2447.42     12804.97    93.45      93.10    84.75    81.37    96.36    0.88\n",
    "  5    8200      16224.26        2482.72     13298.59    93.52      93.19    84.70    81.13    96.33    0.88\n",
    "  5    8400      15862.43        2494.86     12387.48    93.62      93.21    84.80    81.50    96.26    0.88\n",
    "  5    8600      15555.87        2345.07     12120.99    93.63      93.27    84.66    81.26    96.73    0.88\n",
    "  6    8800      16566.15        2287.05     12804.26    93.65      93.32    84.94    81.50    96.06    0.88\n",
    "  6    9000      16152.99        2148.36     11473.04    93.67      93.27    85.33    81.83    96.70    0.89\n",
    "  6    9200      17916.59        2261.99     11944.51    93.64      93.19    84.88    81.50    96.06    0.88\n",
    "  6    9400      18085.37        2131.71     11770.50    93.64      93.24    85.16    81.70    96.29    0.88\n",
    "  6    9600      18234.57        2261.31     11918.78    93.62      93.21    85.04    81.69    96.08    0.88\n",
    "  6    9800      18905.74        2350.16     12344.38    93.62      93.25    85.28    81.77    96.20    0.88\n",
    "  6   10000      19928.89        2436.91     12446.10    93.66      93.27    85.44    82.07    96.02    0.89\n",
    "  7   10200      18905.90        2292.02     11893.45    93.62      93.17    85.31    81.91    96.15    0.89\n",
    "  7   10400      18197.61        1898.43     10801.62    93.58      93.26    84.72    81.52    96.29    0.88\n",
    "  7   10600      20465.24        2118.91     11420.77    93.58      93.25    85.37    81.87    96.29    0.89\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b.**  Veuillez charger le meilleur modèle (pipeline) dans la variable `nlp2` et afficher ses scores sur les données de test.  Comment se comparent les résultats avec les précédents ?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T12:19:43.516461Z",
     "start_time": "2025-04-03T12:19:40.945901Z"
    }
   },
   "source": [
    "# Charger le modèle entraîné\n",
    "nlp2 = spacy.load(\"./myDEPparser1/model-best\")\n",
    "\n",
    "# Calculate both scores for all test data\n",
    "total_examples = []\n",
    "\n",
    "# Get all docs from test data\n",
    "test_docs = list(test_data.get_docs(nlp2.vocab))\n",
    "\n",
    "# Process each document and create examples for scoring\n",
    "for doc in test_docs:\n",
    "    for sent in doc.sents:\n",
    "        # Create a Doc object from the text of the sentence for processing with nlp2\n",
    "        pred_doc = nlp2(sent.text)\n",
    "        # Create an Example object for each sentence\n",
    "        example = Example(pred_doc, sent.as_doc())\n",
    "        total_examples.append(example)\n",
    "\n",
    "# Score all examples\n",
    "scores = full_scorer.score(total_examples)\n",
    "\n",
    "# Display the scores\n",
    "print(f\"UAS (Unlabeled Attachment Score): {scores['dep_uas']:.3f}\")\n",
    "print(f\"LAS (Labeled Attachment Score): {scores['dep_las']:.3f}\")\n",
    "\n",
    "# Compare with the scores from fr_core_news_sm\n",
    "print(\"\\nComparison with fr_core_news_sm scores:\")\n",
    "print(f\"UAS difference: {scores['dep_uas'] - 0.741:.3f}\")  \n",
    "print(f\"LAS difference: {scores['dep_las'] - 0.613:.3f}\")\n",
    "\n",
    "\"\"\"\n",
    "Le modèle entraîné (nlp2) a obtenu les scores suivants sur les données de test :\n",
    "- UAS (Unlabeled Attachment Score) : 0.687\n",
    "- LAS (Labeled Attachment Score) : 0.597\n",
    "\n",
    "En comparaison, le modèle de base fr_core_news_sm avait obtenu :\n",
    "- UAS : 0.741\n",
    "- LAS : 0.613\n",
    "\n",
    "L’analyse des résultats montre que notre modèle personnalisé a des performances légèrement inférieures à fr_core_news_sm. En particulier :\n",
    "\n",
    "- Le UAS est inférieur de 0.054, indiquant que la structure des dépendances est moins bien capturée.\n",
    "\n",
    "- Le LAS est inférieur de 0.016, ce qui signifie que l’étiquetage des relations reste relativement proche du modèle pré-entraîné.\n",
    "\n",
    "Cela suggère que notre modèle a encore une marge d’amélioration. Pour obtenir de meilleurs résultats, il serait pertinent d’augmenter le nombre d’itérations (epoch), d’enrichir les données d’entraînement ou d’utiliser un modèle de base plus performant comme fr_core_news_md ou fr_core_news_lg.\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS (Unlabeled Attachment Score): 0.687\n",
      "LAS (Labeled Attachment Score): 0.597\n",
      "\n",
      "Comparison with fr_core_news_sm scores:\n",
      "UAS difference: -0.054\n",
      "LAS difference: -0.016\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Veuillez afficher les scores détaillés pour chaque type de relation de dépendances, dans un tableau formaté comme au 3b."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T12:22:53.897248Z",
     "start_time": "2025-04-03T12:22:53.886189Z"
    }
   },
   "source": [
    "# Calculate scores for each dependency type\n",
    "scores_by_type = scores['dep_las_per_type']\n",
    "\n",
    "# Sort the types by f score\n",
    "sorted_types = sorted(scores_by_type.items(), key=lambda x: x[1]['f'], reverse=True)\n",
    "\n",
    "# Display types with top f scores\n",
    "print(f\"{'Type':<20} {'Precision':>10} {'Recall':>10} {'F-score':>10}\")\n",
    "print(\"-\" * 52)\n",
    "\n",
    "# Print scores for each type, aligned in columns\n",
    "for dep_type, score in sorted_types:\n",
    "    print(f\"{dep_type:<20} {score['p']:>10.3f} {score['r']:>10.3f} {score['f']:>10.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                  Precision     Recall    F-score\n",
      "----------------------------------------------------\n",
      "det                       0.901      0.768      0.829\n",
      "case                      0.784      0.728      0.755\n",
      "cc                        0.766      0.709      0.736\n",
      "aux                       0.692      0.769      0.728\n",
      "flat:name                 0.662      0.723      0.691\n",
      "aux:pass                  0.615      0.755      0.678\n",
      "nummod                    0.611      0.699      0.652\n",
      "amod                      0.628      0.659      0.643\n",
      "nsubj                     0.681      0.594      0.635\n",
      "cop                       0.690      0.576      0.627\n",
      "nmod                      0.554      0.675      0.609\n",
      "root                      0.484      0.663      0.560\n",
      "obj                       0.491      0.632      0.552\n",
      "advmod                    0.593      0.515      0.551\n",
      "mark                      0.684      0.450      0.543\n",
      "obl                       0.448      0.438      0.443\n",
      "xcomp                     0.312      0.462      0.373\n",
      "acl:relcl                 0.403      0.333      0.365\n",
      "conj                      0.409      0.287      0.337\n",
      "fixed                     0.571      0.183      0.277\n",
      "nsubj:pass                0.355      0.220      0.272\n",
      "appos                     0.179      0.305      0.226\n",
      "expl                      1.000      0.089      0.164\n",
      "acl                       0.183      0.135      0.155\n",
      "advcl                     0.131      0.108      0.118\n",
      "ccomp                     0.000      0.000      0.000\n",
      "parataxis                 0.000      0.000      0.000\n",
      "iobj                      0.000      0.000      0.000\n",
      "obj:agent                 0.000      0.000      0.000\n",
      "aux:caus                  0.000      0.000      0.000\n",
      "dep                       0.000      0.000      0.000\n",
      "nsubj:caus                0.000      0.000      0.000\n",
      "compound                  0.000      0.000      0.000\n",
      "iobj:agent                0.000      0.000      0.000\n",
      "obl:agent                 0.000      0.000      0.000\n",
      "discourse                 0.000      0.000      0.000\n",
      "csubj                     0.000      0.000      0.000\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d.** Quels changements observez-vous en haut (3 premiers labels) et en bas du classement ?  Voyez-vous un label pour lequel les scores n'augmentent pas avec le parser entraîné ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En comparant les scores détaillés avant et après l'entraînement du modèle, on observe plusieurs changements notables :\n",
    "\n",
    "En haut du classement (Top 3 labels) :\n",
    "- \"det\" (déterminant) :\n",
    "    - Avant : F-score = 0.838\n",
    "    - Après : F-score = 0.829\n",
    "  Légère baisse, mais le score reste élevé.\n",
    "\n",
    "- \"case\" (mot de relation, ex: prépositions) :\n",
    "    - Avant : F-score = 0.789\n",
    "    - Après : F-score = 0.755\n",
    "  Baisse de 0.034, indiquant une performance légèrement dégradée.\n",
    "\n",
    "- \"cc\" (conjonction de coordination) :\n",
    "    - Avant : F-score = 0.796\n",
    "    - Après : F-score = 0.736\n",
    "  Perte de 0.060, ce qui montre une dégradation notable.\n",
    "\n",
    "\n",
    "En bas du classement :\n",
    "- Plusieurs labels restent à 0.000 avant et après l'entraînement, comme \"ccomp\" (complément de phrase), \"parataxis\" (juxtaposition), \"iobj\" (objet indirect), \"obj:agent\", \"aux:caus\", etc.\n",
    "\n",
    "- Cela signifie que le modèle n'a pas réussi à améliorer la reconnaissance de ces relations, ce qui pourrait être dû à un manque d'exemples d'entraînement pour ces catégories.\n",
    "\n",
    "\n",
    "Labels qui n'ont pas progressé :\n",
    "- \"expl\" (expletive) :\n",
    "    - Avant : 0.000\n",
    "    - Après : F-score = 0.164\n",
    "  Une petite amélioration, mais le score reste faible.\n",
    "\n",
    "- \"obl\" (complément oblique) :\n",
    "    - Avant : 0.000\n",
    "    - Après : F-score = 0.443\n",
    "  Une nette amélioration, mais cela reste un score moyen.\n",
    "\n",
    "Conclusion :\n",
    "L'entraînement du modèle a globalement dégradé la performance sur les relations les plus fréquentes (comme det, case, cc), tandis que certaines relations plus rares ont légèrement progressé. Cependant, plusieurs labels restent non reconnus. Pour améliorer ces résultats, il faudrait probablement :\n",
    "\n",
    "    - Augmenter le nombre d’itérations (epochs) pour mieux ajuster le modèle.\n",
    "    - Ajouter plus de données d'entraînement, notamment pour les relations sous-représentées.\n",
    "    - Tester avec un modèle de base plus grand (fr_core_news_md ou fr_core_news_lg).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin du Labo.** Veuillez nettoyer ce notebook en gardant seulement les résultats désirés, l'enregistrer, et le soumettre comme devoir sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
